-- MOL Speed Demo: Benchmark vs typical Python patterns
-- This demonstrates MOL's efficient pipeline execution

-- 1. Functional pipeline - process 10000 items in one chain
let data be range(10000)

let start be clock()

-- Map, filter, reduce in a single pipeline
define is_even(n)
  return n % 2 is 0
end

define square(x)
  return x * x
end

let evens be filter(data, is_even)
let squared be map(evens, square)
let total be sum(squared)

let elapsed be clock() - start

show "=== MOL Speed Benchmark ==="
show ""
show "Processed 10,000 items through filter → map → sum"
show "Result: " + to_text(total)
show "Time: " + to_text(elapsed) + " seconds"
show ""

-- 2. String processing pipeline  
let start2 be clock()

let words be ["hello", "world", "mol", "is", "fast", "language", "built", "for", "ai", "pipelines"]
let i be 0
while i < 1000 do
  let processed be join(words, " ") |> upper |> lower |> trim
  set i to i + 1
end

let elapsed2 be clock() - start2
show "String pipeline (1000 iterations): " + to_text(elapsed2) + " seconds"
show ""

-- 3. RAG pipeline demo
let start3 be clock()

let doc be Document("benchmark.txt", "Machine learning is transforming every industry. Deep learning neural networks process vast amounts of data. Natural language processing enables computers to understand human language. Computer vision allows machines to interpret visual information. Reinforcement learning trains agents through trial and error.")

let index be doc |> chunk(80) |> embed |> store("bench_index")

let results be retrieve("What is deep learning?", "bench_index", 3)

let elapsed3 be clock() - start3
show "Full RAG pipeline (chunk→embed→store→retrieve): " + to_text(elapsed3) + " seconds"
show ""
show "=== All benchmarks complete ==="
